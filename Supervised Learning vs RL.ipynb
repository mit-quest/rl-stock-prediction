{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supervised Learning is a practical Machine Learning approach where a model is trained to learn the relationship between an input and an output. In supervised learning we first start with a data set containing training examples with associated correct labels. In our case, this is the stock data that we are using. Our supervised learning takes in hundreds of values of stock pricing for a given day, and is then trained to learn the relationship between stock price per day. More formally, weâ€™d like our model to approximate the relationship, lets call it f, between the number of days X and corresponding to stock price.\n",
    "\n",
    "In our approach, there are two main factors we consider. The first is analyzing future profitability on the basis of current performance. (i.e. given our current earnings, how can we decide to buy and or sell?). Secondly, how can we use a statistical analysis to identify trends of the market and make beneficial predictions for the next day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "/Users/dolapoadedokun/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n/Users/dolapoadedokun/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n/Users/dolapoadedokun/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n/Users/dolapoadedokun/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n/Users/dolapoadedokun/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n/Users/dolapoadedokun/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n/Users/dolapoadedokun/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n/Users/dolapoadedokun/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n/Users/dolapoadedokun/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n/Users/dolapoadedokun/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n/Users/dolapoadedokun/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n/Users/dolapoadedokun/anaconda3/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\nUsing TensorFlow backend.\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras import optimizers\n",
    "from keras.callbacks import CSVLogger\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "import os\n",
    "\n",
    "TIME_STEPS = 30\n",
    "BATCH_SIZE = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Stock Data\n",
    "\n",
    "We start by reading five major stocks, Microsft, Google,  Amazon, IBM, and Apple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "msft = pd.read_csv(\"./Individual_Stock_Data/MSFT.csv\")\n",
    "googl = pd.read_csv(\"./Individual_Stock_Data/GOOGL.csv\")\n",
    "amzn = pd.read_csv(\"./Individual_Stock_Data/AMZN.csv\")\n",
    "ibm = pd.read_csv(\"./Individual_Stock_Data/IBM.csv\")\n",
    "aapl = pd.read_csv(\"./Individual_Stock_Data/AAPL.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Open</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Close</th>\n      <th>Adj Close</th>\n      <th>Volume</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2010-01-04</td>\n      <td>30.62</td>\n      <td>31.10</td>\n      <td>30.59</td>\n      <td>30.95</td>\n      <td>24.53</td>\n      <td>38409100</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2010-01-05</td>\n      <td>30.85</td>\n      <td>31.10</td>\n      <td>30.64</td>\n      <td>30.96</td>\n      <td>24.53</td>\n      <td>49749600</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2010-01-06</td>\n      <td>30.88</td>\n      <td>31.08</td>\n      <td>30.52</td>\n      <td>30.77</td>\n      <td>24.38</td>\n      <td>58182400</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2010-01-07</td>\n      <td>30.63</td>\n      <td>30.70</td>\n      <td>30.19</td>\n      <td>30.45</td>\n      <td>24.13</td>\n      <td>50559700</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2010-01-08</td>\n      <td>30.28</td>\n      <td>30.88</td>\n      <td>30.24</td>\n      <td>30.66</td>\n      <td>24.30</td>\n      <td>51197400</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "         Date   Open   High    Low  Close  Adj Close    Volume\n0  2010-01-04  30.62  31.10  30.59  30.95      24.53  38409100\n1  2010-01-05  30.85  31.10  30.64  30.96      24.53  49749600\n2  2010-01-06  30.88  31.08  30.52  30.77      24.38  58182400\n3  2010-01-07  30.63  30.70  30.19  30.45      24.13  50559700\n4  2010-01-08  30.28  30.88  30.24  30.66      24.30  51197400"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msft.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(msft[\"Open\"])\n",
    "plt.plot(msft[\"Close\"])\n",
    "plt.plot(msft[\"High\"])\n",
    "plt.plot(msft[\"Low\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize Data\n",
    "\n",
    "Normlaizing the data simply helps the algorithm in converging i.e. to find local/ global minimum efficiently, for future predictions. Before fully normalizing the data, we also split the dataset into training and testing data sets. As expected, the training dataset is used to train the model, and the testing dataset is used to observe the performance of the model after the training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(msft, train_size=0.84, test_size=0.16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Open</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Close</th>\n      <th>Adj Close</th>\n      <th>Volume</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2010-01-04</td>\n      <td>30.62</td>\n      <td>31.10</td>\n      <td>30.59</td>\n      <td>30.95</td>\n      <td>24.53</td>\n      <td>38409100</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2010-01-05</td>\n      <td>30.85</td>\n      <td>31.10</td>\n      <td>30.64</td>\n      <td>30.96</td>\n      <td>24.53</td>\n      <td>49749600</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2010-01-06</td>\n      <td>30.88</td>\n      <td>31.08</td>\n      <td>30.52</td>\n      <td>30.77</td>\n      <td>24.38</td>\n      <td>58182400</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2010-01-07</td>\n      <td>30.63</td>\n      <td>30.70</td>\n      <td>30.19</td>\n      <td>30.45</td>\n      <td>24.13</td>\n      <td>50559700</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2010-01-08</td>\n      <td>30.28</td>\n      <td>30.88</td>\n      <td>30.24</td>\n      <td>30.66</td>\n      <td>24.30</td>\n      <td>51197400</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "         Date   Open   High    Low  Close  Adj Close    Volume\n0  2010-01-04  30.62  31.10  30.59  30.95      24.53  38409100\n1  2010-01-05  30.85  31.10  30.64  30.96      24.53  49749600\n2  2010-01-06  30.88  31.08  30.52  30.77      24.38  58182400\n3  2010-01-07  30.63  30.70  30.19  30.45      24.13  50559700\n4  2010-01-08  30.28  30.88  30.24  30.66      24.30  51197400"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>2017-12-26</td>\n",
       "      <td>85.31</td>\n",
       "      <td>85.53</td>\n",
       "      <td>85.03</td>\n",
       "      <td>85.40</td>\n",
       "      <td>83.28</td>\n",
       "      <td>9891200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>2017-12-27</td>\n",
       "      <td>85.65</td>\n",
       "      <td>85.98</td>\n",
       "      <td>85.22</td>\n",
       "      <td>85.71</td>\n",
       "      <td>83.58</td>\n",
       "      <td>14678000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>2017-12-28</td>\n",
       "      <td>85.90</td>\n",
       "      <td>85.93</td>\n",
       "      <td>85.55</td>\n",
       "      <td>85.72</td>\n",
       "      <td>83.59</td>\n",
       "      <td>10594300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>2017-12-29</td>\n",
       "      <td>85.63</td>\n",
       "      <td>86.05</td>\n",
       "      <td>85.50</td>\n",
       "      <td>85.54</td>\n",
       "      <td>83.42</td>\n",
       "      <td>18717400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>86.13</td>\n",
       "      <td>86.31</td>\n",
       "      <td>85.50</td>\n",
       "      <td>85.95</td>\n",
       "      <td>83.82</td>\n",
       "      <td>22483800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date   Open   High    Low  Close  Adj Close    Volume\n",
       "2009  2017-12-26  85.31  85.53  85.03  85.40      83.28   9891200\n",
       "2010  2017-12-27  85.65  85.98  85.22  85.71      83.58  14678000\n",
       "2011  2017-12-28  85.90  85.93  85.55  85.72      83.59  10594300\n",
       "2012  2017-12-29  85.63  86.05  85.50  85.54      83.42  18717400\n",
       "2013  2018-01-02  86.13  86.31  85.50  85.95      83.82  22483800"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training and Testing the Data. \n",
    "\n",
    "As part of the normalization mentioned earlier, we transofrm the data, intialize th emodel, and train and test the model. We run the function here but each major part is broken down in the following parts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test(data, stock_name=\"\", load_model=False):\n",
    "    df_train, df_test = train_test_split(data, train_size=0.84, test_size=0.16, shuffle=False)\n",
    "    \n",
    "    train_cols = [\"Open\", \"High\", \"Low\", \"Adj Close\", \"Volume\"]\n",
    "    print(\"Train and Test Size:\", len(df_train), len(df_test))\n",
    "    x = df_train.loc[:,train_cols].values\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    \n",
    "    # Transforming Data\n",
    "    x_train = min_max_scaler.fit_transform(x)\n",
    "    x_test = min_max_scaler.transform(df_test.loc[:,train_cols])\n",
    "    print(df_train[train_cols])\n",
    "\n",
    "    \n",
    "\n",
    "    def build_timeseries(mat, y_col_index):\n",
    "        # y_col_index is the index of column that would act as output column\n",
    "        # total number of time-series samples would be len(mat) - TIME_STEPS\n",
    "        dim_0, dim_1 = mat.shape[0] - TIME_STEPS, mat.shape[1]\n",
    "        x = np.zeros((dim_0, TIME_STEPS, dim_1))\n",
    "        y = np.zeros((dim_0,))\n",
    "        for i in range(dim_0):\n",
    "            x[i] = mat[i:TIME_STEPS+i]\n",
    "            y[i] = mat[TIME_STEPS+i, y_col_index]\n",
    "        print(\"length of time-series i/o\",x.shape,y.shape)\n",
    "        return x, y\n",
    "\n",
    "    def trim_dataset(mat, batch_size):\n",
    "        \"\"\"\n",
    "        trims dataset to a size that's divisible by BATCH_SIZE\n",
    "        \"\"\"\n",
    "        no_of_rows_drop = mat.shape[0]%batch_size\n",
    "        if(no_of_rows_drop > 0):\n",
    "            return mat[:-no_of_rows_drop]\n",
    "        else:\n",
    "            return mat\n",
    "\n",
    "    x_t, y_t = build_timeseries(x_train, 3)\n",
    "    x_t = trim_dataset(x_t, BATCH_SIZE)\n",
    "    y_t = trim_dataset(y_t, BATCH_SIZE)\n",
    "    x_temp, y_temp = build_timeseries(x_test, 3)\n",
    "    x_val, x_test_t = np.split(trim_dataset(x_temp, BATCH_SIZE),2)\n",
    "    y_val, y_test_t = np.split(trim_dataset(y_temp, BATCH_SIZE),2)\n",
    "    # print(\"Test size\", x_test_t.shape, y_test_t.shape, x_val.shape, y_val.shape)\n",
    "    \n",
    "    lstm_model = Sequential()\n",
    "    lstm_model.add(LSTM(100, batch_input_shape=(BATCH_SIZE, TIME_STEPS, x_t.shape[2]), dropout=0.0, recurrent_dropout=0.0, stateful=True,     kernel_initializer='random_uniform'))\n",
    "    lstm_model.add(Dropout(0.4))\n",
    "    lstm_model.add(Dense(40,activation='relu')) # 40\n",
    "    lstm_model.add(Dense(1,activation='sigmoid')) # \n",
    "    optimizer = optimizers.RMSprop(lr=0.001)\n",
    "    lstm_model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "    \n",
    "    csv_logger = CSVLogger(\"stock_supervised.log\", append=True)\n",
    "\n",
    "    history = lstm_model.fit(x_t, y_t, epochs=50, verbose=2, batch_size=BATCH_SIZE, #50\n",
    "                            shuffle=False, validation_data=(trim_dataset(x_val, BATCH_SIZE),\n",
    "                            trim_dataset(y_val, BATCH_SIZE)), callbacks=[csv_logger])\n",
    "    \n",
    "    lstm_model.save(\"SL_stock_model.h5\")\n",
    "    \n",
    "    from keras.models import load_model\n",
    "\n",
    "    y_pred = lstm_model.predict(trim_dataset(x_test_t, BATCH_SIZE), batch_size=BATCH_SIZE)\n",
    "    y_pred = y_pred.flatten()\n",
    "    y_test_t = trim_dataset(y_test_t, BATCH_SIZE)\n",
    "    error = mean_squared_error(y_test_t, y_pred)\n",
    "    #print(\"Error is\", error, y_pred.shape, y_test_t.shape)\n",
    "\n",
    "    # convert the predicted value to range of real data\n",
    "    y_pred_org = (y_pred * min_max_scaler.data_range_[3]) + min_max_scaler.data_min_[3]\n",
    "    # min_max_scaler.inverse_transform(y_pred)\n",
    "    y_test_t_org = (y_test_t * min_max_scaler.data_range_[3]) + min_max_scaler.data_min_[3]\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(y_pred_org)\n",
    "    plt.plot(y_test_t_org)\n",
    "    plt.title('Prediction vs Real Stock Price ' + stock_name)\n",
    "    plt.ylabel('Price')\n",
    "    plt.xlabel('Days')\n",
    "    plt.legend(['Prediction', 'Real'], loc='upper left')\n",
    "    plt.savefig('pred_vs_real_BS_'+stock_name+'.png')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return y_test_t_org, y_pred_org"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build Time-Series Structure\n",
    "\n",
    "One of the most improtant aspects of creating an effective model is the actual algorithm we use. Here, we are using an LSTM model specifically for its well-suitment to process and predict time series given values that change over an unkown period of time. \n",
    "\n",
    "LSTMs consume input in format of a three-dimensional array; [ batch_size, time_steps, Features ]\n",
    "\n",
    "Batch Size is a number representing the number of samples of data the nueral net should see before re-adjusting and updating weights. \n",
    "\n",
    "The Time Steps basically define how many units back in time you want your network to see.\n",
    "\n",
    "\n",
    "Features is the number of attributes used to represent each time step in our training columns.\n",
    "\n",
    "We label these parameters in the initializtion of the project.\n",
    "\n",
    "\n",
    "In this next cell, we run through all of the defined steps above.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Converting Data to Time Series\n",
    "\n",
    "In this step, our goal is to convert our data into a format to pass into our model. We want our model to look back on our 'time_step' amount of days and want to represent our data set accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_timeseries(mat, y_col_index):\n",
    "    # y_col_index is the index of column that would act as output column\n",
    "    # total number of time-series samples would be len(mat) - TIME_STEPS\n",
    "    dim_0, dim_1 = mat.shape[0] - TIME_STEPS, mat.shape[1]\n",
    "    x = np.zeros((dim_0, TIME_STEPS, dim_1))\n",
    "    y = np.zeros((dim_0,))\n",
    "    for i in range(dim_0):\n",
    "        x[i] = mat[i:TIME_STEPS+i]\n",
    "        y[i] = mat[TIME_STEPS+i, y_col_index]\n",
    "    print(\"length of time-series i/o\",x.shape,y.shape)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Trimming the Dataset\n",
    "\n",
    "After converting our data, we also want to trim the data to remove any excess odd samples. For example, if we have 51 samples and our batchsize is 25, we would need to trim the excess sample data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_dataset(mat, batch_size):\n",
    "    \"\"\"\n",
    "    trims dataset to a size that's divisible by BATCH_SIZE\n",
    "    \"\"\"\n",
    "    no_of_rows_drop = mat.shape[0]%batch_size\n",
    "    if(no_of_rows_drop > 0):\n",
    "        return mat[:-no_of_rows_drop]\n",
    "    else:\n",
    "        return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-635de64085ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "x_train.shape, x_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Forming Datasets\n",
    "\n",
    "In this step, we simply form our train, validation and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-7f6513e18117>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mx_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_timeseries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0mx_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrim_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0my_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrim_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "x_t, y_t = build_timeseries(x_train, 3)\n",
    "x_t = trim_dataset(x_t, BATCH_SIZE)\n",
    "y_t = trim_dataset(y_t, BATCH_SIZE)\n",
    "x_temp, y_temp = build_timeseries(x_test, 3)\n",
    "x_val, x_test_t = np.split(trim_dataset(x_temp, BATCH_SIZE),2)\n",
    "y_val, y_test_t = np.split(trim_dataset(y_temp, BATCH_SIZE),2)\n",
    "print(\"Test size\", x_test_t.shape, y_test_t.shape, x_val.shape, y_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = Sequential()\n",
    "lstm_model.add(LSTM(100, batch_input_shape=(BATCH_SIZE, TIME_STEPS, x_t.shape[2]), dropout=0.0, recurrent_dropout=0.0, stateful=True,     kernel_initializer='random_uniform'))\n",
    "lstm_model.add(Dropout(0.4))\n",
    "lstm_model.add(Dense(20,activation='relu'))\n",
    "lstm_model.add(Dense(1,activation='sigmoid'))\n",
    "optimizer = optimizers.RMSprop(lr=0.001)\n",
    "lstm_model.compile(loss='mean_squared_error', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lstm_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-3ae31b57c8d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcsv_logger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCSVLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"stock_supervised.log\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m history = lstm_model.fit(x_t, y_t, epochs=50, verbose=2, batch_size=BATCH_SIZE, #50\n\u001b[0m\u001b[1;32m      4\u001b[0m                         shuffle=False, validation_data=(trim_dataset(x_val, BATCH_SIZE),\n\u001b[1;32m      5\u001b[0m                         trim_dataset(y_val, BATCH_SIZE)), callbacks=[csv_logger])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lstm_model' is not defined"
     ]
    }
   ],
   "source": [
    "csv_logger = CSVLogger(\"stock_supervised.log\", append=True)\n",
    "\n",
    "history = lstm_model.fit(x_t, y_t, epochs=50, verbose=2, batch_size=BATCH_SIZE, #50\n",
    "                        shuffle=False, validation_data=(trim_dataset(x_val, BATCH_SIZE),\n",
    "                        trim_dataset(y_val, BATCH_SIZE)), callbacks=[csv_logger])\n",
    "lstm_model.save(\"SL_stock_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating, Training, and Testing the Model\n",
    "\n",
    "Here, we initialize the LSTM Model and train it using our datasets. Then we test it on our test dataset and plot its prediction trajectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error is 0.01995023730488854 (180,) (180,)\n",
      "[103.09269  102.25271  101.4452   100.53778  100.45001   98.88178\n",
      "  97.40711   97.73007   97.64805   98.29788  100.611984 100.28443\n",
      " 100.118195 100.192665  99.48604 ]\n",
      "[112.79 112.13 110.85 112.26 106.16 105.91 109.57 107.6  111.   110.71\n",
      " 108.5  108.66 109.63 108.1  102.32]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "y_pred = lstm_model.predict(trim_dataset(x_test_t, BATCH_SIZE), batch_size=BATCH_SIZE)\n",
    "y_pred = y_pred.flatten()\n",
    "y_test_t = trim_dataset(y_test_t, BATCH_SIZE)\n",
    "error = mean_squared_error(y_test_t, y_pred)\n",
    "print(\"Error is\", error, y_pred.shape, y_test_t.shape)\n",
    "\n",
    "# convert the predicted value to range of real data\n",
    "y_pred_org = (y_pred * min_max_scaler.data_range_[3]) + min_max_scaler.data_min_[3]\n",
    "# min_max_scaler.inverse_transform(y_pred)\n",
    "y_test_t_org = (y_test_t * min_max_scaler.data_range_[3]) + min_max_scaler.data_min_[3]\n",
    "\n",
    "print(y_pred_org[0:15])\n",
    "print(y_test_t_org[0:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred_org' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-e64df0e2fcc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred_org\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_t_org\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Prediction vs Real Stock Price'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_pred_org' is not defined"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.figure()\n",
    "plt.plot(y_pred_org)\n",
    "plt.plot(y_test_t_org)\n",
    "plt.title('Prediction vs Real Stock Price')\n",
    "plt.ylabel('Price')\n",
    "plt.xlabel('Days')\n",
    "plt.legend(['Prediction', 'Real'], loc='upper left')\n",
    "plt.show()\n",
    "plt.savefig('pred_vs_real_BS_.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Judging How Effective Our Model Is\n",
    "\n",
    "In the following sections, we plot and detail the performance of our model. We also discuss the changes introduced by shifting the value of episolon or the threshhold for our model to buy or sell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44129027913021124\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def coeff_determination(y_true, y_pred):\n",
    "\n",
    "    SS_res =K.sum(K.square( y_true-y_pred ))\n",
    "    SS_tot = K.sum(K.square( y_true - np.mean(y_true) ) )\n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
    "\n",
    "R_2 = coeff_determination(y_test_t_org, y_pred_org)\n",
    "with tf.Session() as sess:  \n",
    "    print(R_2.eval()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred_org' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-9258245665db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred_org\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_test_t_org\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpositions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprofits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmax_len_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_pred_org' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred = y_pred_org\n",
    "y = y_test_t_org\n",
    "positions = [y[0]]\n",
    "profits = []\n",
    "max_len_p = 0\n",
    "eps = 0.02 # Vary this between 0.01 and 0.05 to maximize profit\n",
    "epsilons = np.arange(0, 0.05, .001)\n",
    "max_pos = []\n",
    "for eps in epsilons:\n",
    "    profit= 0\n",
    "    for t in range(1,len(y)):\n",
    "        if y_pred[t] > y[t-1] + eps*y[t-1]:\n",
    "            positions.append(y[t])\n",
    "        elif y_pred[t] < y[t-1] - eps*y[t-1]:\n",
    "            for p in positions:\n",
    "                profit += (y[t] - p)\n",
    "            positions = []\n",
    "        max_len_p = max(max_len_p, len(positions))\n",
    "    profits.append(profit)\n",
    "    max_pos.append(max_len_p)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epsilons, profits)\n",
    "plt.title('Profit maximization')\n",
    "plt.ylabel('Profits')\n",
    "plt.xlabel('Epsilon')\n",
    "plt.legend(['Profits', 'Epsilon'], loc='upper left')\n",
    "plt.show()\n",
    "print(\"Max Profits:\", max(profits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we change the epsilon value, we essentially change the range we can choose whether or not to buy or sell at, rather than hold. From these results, we can see that our maximum epsilon value is around 0.02, so we buy a stock when our predicted price is more than 2% higher than what it was the day before, and we sell if our maximum epsilon value is around 2% lower.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Train and Test Size: 2009 383\n       Open   High    Low  Adj Close    Volume\n0     30.62  31.10  30.59      24.53  38409100\n1     30.85  31.10  30.64      24.53  49749600\n2     30.88  31.08  30.52      24.38  58182400\n3     30.63  30.70  30.19      24.13  50559700\n4     30.28  30.88  30.24      24.30  51197400\n...     ...    ...    ...        ...       ...\n2004  87.12  87.50  86.23      84.24  22283800\n2005  86.35  86.35  85.27      83.70  23524800\n2006  86.20  86.30  84.71      83.40  23674900\n2007  86.05  86.10  85.40      83.38  17990700\n2008  85.40  85.63  84.92      83.39  14145800\n\n[2009 rows x 5 columns]\nlength of time-series i/o (1979, 30, 5) (1979,)\nlength of time-series i/o (353, 30, 5) (353,)\nTrain on 1950 samples, validate on 150 samples\nEpoch 1/50\n - 2s - loss: 0.0119 - val_loss: 0.0703\nEpoch 2/50\n - 1s - loss: 0.0322 - val_loss: 0.0723\nEpoch 3/50\n - 1s - loss: 0.0119 - val_loss: 0.0715\nEpoch 4/50\n - 1s - loss: 0.0064 - val_loss: 0.0724\nEpoch 5/50\n - 1s - loss: 0.0041 - val_loss: 0.0580\nEpoch 6/50\n - 1s - loss: 0.0043 - val_loss: 0.0767\nEpoch 7/50\n - 1s - loss: 0.0035 - val_loss: 0.0584\nEpoch 8/50\n - 1s - loss: 0.0032 - val_loss: 0.0617\nEpoch 9/50\n - 1s - loss: 0.0030 - val_loss: 0.0621\nEpoch 10/50\n - 1s - loss: 0.0028 - val_loss: 0.0553\nEpoch 11/50\n - 1s - loss: 0.0025 - val_loss: 0.0492\nEpoch 12/50\n - 1s - loss: 0.0038 - val_loss: 0.0679\nEpoch 13/50\n - 1s - loss: 0.0023 - val_loss: 0.0761\nEpoch 14/50\n - 1s - loss: 0.0021 - val_loss: 0.0620\nEpoch 15/50\n - 1s - loss: 0.0020 - val_loss: 0.0585\nEpoch 16/50\n - 1s - loss: 0.0022 - val_loss: 0.0655\nEpoch 17/50\n - 1s - loss: 0.0020 - val_loss: 0.0538\nEpoch 18/50\n - 1s - loss: 0.0022 - val_loss: 0.0727\nEpoch 19/50\n - 1s - loss: 0.0017 - val_loss: 0.0525\nEpoch 20/50\n - 1s - loss: 0.0018 - val_loss: 0.0698\nEpoch 21/50\n - 1s - loss: 0.0016 - val_loss: 0.0571\nEpoch 22/50\n - 1s - loss: 0.0016 - val_loss: 0.0564\nEpoch 23/50\n - 1s - loss: 0.0013 - val_loss: 0.0580\nEpoch 24/50\n - 1s - loss: 0.0023 - val_loss: 0.0592\nEpoch 25/50\n - 1s - loss: 0.0013 - val_loss: 0.0607\nEpoch 26/50\n - 1s - loss: 0.0013 - val_loss: 0.0592\nEpoch 27/50\n - 1s - loss: 0.0015 - val_loss: 0.0623\nEpoch 28/50\n - 1s - loss: 0.0012 - val_loss: 0.0497\nEpoch 29/50\n - 1s - loss: 0.0010 - val_loss: 0.0621\nEpoch 30/50\n - 1s - loss: 0.0015 - val_loss: 0.0928\nEpoch 31/50\n - 1s - loss: 0.0012 - val_loss: 0.0733\nEpoch 32/50\n - 1s - loss: 8.9637e-04 - val_loss: 0.1295\nEpoch 33/50\n"
    }
   ],
   "source": [
    "msft_y, msft_y_pred = train_and_test(msft, \"MSFT\")\n",
    "googl_y, googl_y_pred = train_and_test(googl, \"GOOGL\")\n",
    "amzn_y, amzn_y_pred = train_and_test(amzn, \"AMZN\")\n",
    "ibm_y, ibm_y_pred = train_and_test(ibm, \"IBM\")\n",
    "aapl_y, aapl_y_pred = train_and_test(aapl, \"AAPL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}